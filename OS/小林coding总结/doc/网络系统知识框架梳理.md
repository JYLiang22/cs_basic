# 零拷贝

没有DMA技术之前，CPU需要参与整个I/O过程，包括把数据从磁盘控制器的缓冲区搬运到CPU的内核缓冲区(pagecache)，再把数据从内核缓冲区搬运到用户缓冲区。DMA技术出现后，CPU只负责把数据从内核缓冲区搬运到用户缓冲区。<br>
结合上面的过程，使用传统的I/O在服务器和客户端发送数据时，需要两次系统调用(read和write)、四次状态切换、四次拷贝。这四次拷贝中有两次是磁盘和内核之间的拷贝、两次是内核和用户空间的拷贝。其中磁盘和内核之间的拷贝是必须的，因为用户空间没有权限访问磁盘或网卡。但是内核和用户空间的拷贝有点冗余了，因为数据在用户空间不会进行加工。这就引出了零拷贝，指的是不需要用户空间和内核空间进行拷贝。<br>

两种方法：

1. mmap+write：使用mmap代替read，这样就可以避免数据从内核空间拷贝到用户空间，但还是会出现从一个内核缓冲区拷贝到另一个内核缓冲区，这个拷贝也是没必要的。而且这个方法优化不明显，依旧是两次系统调用、四次状态切换、三次拷贝，只减少了一次拷贝。
2. sendfile：一次系统调用、两次切换、三次拷贝，但是CPU拷贝仍然是没必要的。

真正的零拷贝技术：网卡支持SG-DMA(The Scatter-Gather Direct Memory Access)，可以直接避免数据在内核缓冲区的拷贝，把数据直接从内核缓冲区拷贝到网卡的缓冲区，从而实现一次系统调用、两次切换、两次拷贝，真正做到不需要CPU拷贝数据。<br>

使用内核缓冲区(pagecache)的优势：缓存最近访问的数据+预读功能。<br>
但是使用pagecache进行大文件传输的时候，会导致预读失效和缓存污染的问题(如何解决？[内存管理](%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%9F%A5%E8%AF%86%E6%A1%86%E6%9E%B6%E6%A2%B3%E7%90%86.md))，使用异步I/O+直接I/O解决这个问题，绕开pagecache。<br>


# IO 多路复用：select poll epoll

参见项目文件，这里已经说得很清楚了，结合自己的项目理解[面试题](https://github.com/JYLiang22/TinyWebServer-With-CoroLib/blob/main/project/Linux%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BC%80%E5%8F%91/%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/%E9%A1%B9%E7%9B%AE%E6%A1%86%E6%9E%B6%E5%88%86%E6%9E%90/%E9%9D%A2%E8%AF%95%E9%A2%98.md#%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B%E7%9B%B8%E5%85%B3)<br>


# 高性能网络模式：Reactor 和 Proactor

## 演进

首先从一个很实际的场景出发：如果一个服务器要服务多个客户端，应该怎么做？<br>

最直接的做法就是为每一条连接创建线程，这个方法的优缺点如下：

1. 优点：简单
2. 缺点：当不断有连接到来时，需要不停地创建和销毁线程，这样会带来性能开销、也会造成资源浪费

针对上面这个问题的缺点，可以创建一个 **线程池**，优缺点如下：

1. 优点：可以避免线程频繁地创建和销毁，从而让一个线程去处理多个连接的业务
2. 问题：线程在处理连接时，一般采用 **read -> 业务处理 -> send** 的流程，如果当前连接没有数据可读，就会使得线程阻塞在 **read** 操作上，这样线程就没办法继续处理其他连接的业务

上述问题的原因还是在于 **socket 默认情况是阻塞 I/O**，所以最简单的方式就是 **将 socket 改成非阻塞**，然后线程不断地轮询调用 read 操作来判断是否有数据。优缺点如下：

1. 优点：简单粗暴，可以解决阻塞的问题
2. 缺点：轮询是要消耗 CPU 的，而且随着一个 线程处理的连接越多，轮询的效率就会越低

上面的问题在于，**线程并不知道当前连接是否有数据可读，从而需要每次通过 read 去试探**<br>
解决这一问题的方法就是 [**I/O多路复用**](<IO 多路复用：select poll epoll.md>)<br>

但是这个方法也有缺点： **I/O 多路复用接口写网络程序是面向过程的方式写代码的，这样开发的效率不高。**<br>
所以基于面向对象的思想，对 I/O 多路复用作了一层封装，即 **Reactor 模式**。<br>
但是小林觉得这个名字更贴切：Dispatcher 模式，即 I/O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程。<br>

Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成：

1. Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件
2. 处理资源池负责处理事件，如 read -> 业务逻辑 -> send

## Reactor

### 单 Reactor 单进程 / 线程

有三个部分组成，具体工作流程和详细细节可以看博客图。

1. Reactor 对象的作用是监听和分发事件
2. Acceptor 对象的作用是获取连接
3. Handler 对象的作用是处理业务

优缺点如下：

1. 优点：全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争
2. 缺点
   1. 只有一个进程，无法充分利用 多核 CPU 的性能
   2. Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟

**不适用计算机密集型的场景，只适用于业务处理非常快速的场景。**

### 单 Reactor 多线程 / 多进程

和上一个的主要区别在于：Handler 不再负责处理业务，而是只负责数据的发送和接收(即read和send)，业务处理由 **线程池** 来负责处理。<br>

优缺点以及问题所在：

1. 优点：能够充分利用多核 CPU 的能力
2. 问题
   1. 既然引入多线程，那么自然就带来了多线程竞争资源的问题，即子线程完成业务处理后，要把结果传递给主线程的 Handler 进行发送，这里涉及共享数据的竞争。可以使用锁解决
   2. 因为只有一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方

### 多 Reactor 多进程 / 线程

在解决了可以处理高并发的同时，还降低了耦合度。

## Proactor

前面提到的 Reactor 是 **非阻塞同步网络模式**，而 Proactor 是 **异步网络模式**<br>
区分以下几个概念，具体可以看博客图，这样理解得更深入。

1. 阻塞 I/O
2. 非阻塞 I/O
3. 异步 I/O

还举了个食堂打饭的例子帮助理解！<br>

Reactor 和 Proactor 的区别：

1. Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件，可以理解为来了事件操作系统通知应用进程，让应用进程来处理
2. Proactor 是异步网络模式， 感知的是已完成的读写事件，可以理解为来了事件操作系统来处理，处理完再通知应用进程


# 一致性哈希

其实是解决负载均衡问题的一种方法。因为网站大多数都是使用服务器集群给用户提供服务的，这种情况下需要结合服务器的情况合理分配客户端的请求。<br>
最简单的方法是让外界的请求轮询内部服务器集群；再进一步考虑到服务器的硬件配置区别，可以使用加权轮询。这两种方法的使用场景是每个服务器节点存储的数据必须一致，但为了提高系统的容量，目前的服务器集群都是使用分布式存储的方法，即每个节点存储的数据是不一样的。<br>
应对这样的分布式系统，理所当然会想到哈希算法。因为对同一个关键字进行哈希计算会得到相同的值，这样可以确保同一个客户端请求每次都能访问到他需要服务器。但是这种方法存在一个十分致命的问题：分布式系统在进行扩容或缩容的时候，映射关系会发生改变，这个时候必须迁移改变了映射关系的数据。也就是说把哈希算法应用到分布式系统中，在系统容量发生变化时，会出现过多的数据迁移的问题。<br>
这个时候就可以使用一致性哈希算法去解决上述问题。它将存储节点和数据都映射到一个首位相连的哈希环上，即它会进行两步哈希：

1. 对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希
2. 当对数据进行存储或访问时，对数据进行哈希映射。映射的结果值往顺时针的方向的找到第一个节点，就是存储该数据的节点。

这种情况下，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。但是一致性哈希算法并不保证节点可以在哈希环上均匀分布，这样会导致大量请求集中在一个节点上。在这种节点分布不均匀的情况下，进行容量变化时，哈希环上相邻节点容易受到过大影响而产生雪崩式连锁反应。<br>
为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。例如Nginx的一致性哈希方法，每个权重为1的真实节点就有160个虚拟节点。<br>
引入虚拟节点后，可以提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。<br>


# Nginx

Nginx 是一款轻量级的 HTTP 服务器，采用事件驱动的异步非阻塞(什么是？)处理方式框架，这让其具有极好的 IO 性能，时常用于服务端的反向代理和负载均衡。使用Nginx的几大好处：

1. 动静分离，即静态资源的请求直接从Nginx服务器设定的根目录路径去取对应的资源，动态资源的请求则到后台去取。这样做可以减轻后台服务器的压力、实现前后端的分离，同时可以提升用户体验。因为用户发出一个请求，就可以马上得到静态资源的返回。
2. 反向代理和正向代理
   通信双方可以抽象为客户端和服务端，反向代理就是在服务端部署代理服务器。当客户端向服务端发送请求的时候，就可以通过服务端代理返回数据，而不需要知道数据具体是从哪一个服务器得到的。<br>
   正向代理就是在客户端部署代理服务器，这样当客户端给服务器发送请求的时候，其实是通过代理服务器去给服务器发送请求并返回数据的。<br>
   为什么不能直接访问服务器而要设置代理服务器，使用代理服务器去访问？有以下几个原因：

   1. 突破访问限制，如访问国外网站
   2. 实现上面所说的负载均衡和缓存
   3. 提供网络访问控制和安全性：代理服务器充当客户端和目标服务器之间的中间人，可以对网络请求进行过滤和监控。通过设置代理服务器，管理员可以控制用户对特定网站的访问，并进行恶意网站的过滤，提高网络安全性。
