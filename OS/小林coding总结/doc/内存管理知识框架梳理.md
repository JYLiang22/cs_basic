- [为什么要有内存管理](#为什么要有内存管理)
  - [虚拟内存](#虚拟内存)
  - [内存分段](#内存分段)
  - [内存分页](#内存分页)
    - [多级页表](#多级页表)
    - [TLB](#tlb)
  - [段页式内存管理](#段页式内存管理)
- [malloc如何分配内存](#malloc如何分配内存)
- [内存满了会发生什么](#内存满了会发生什么)
- [在 4GB 物理内存的机器上，申请 8G 内存会怎么样](#在-4gb-物理内存的机器上申请-8g-内存会怎么样)
- [如何避免预读失效和缓存污染](#如何避免预读失效和缓存污染)


# 为什么要有内存管理

![Alt text](../image/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86.png)<br>


## 虚拟内存

从单片机的例子说起，它是没有操作系统的，**直接操作内存的物理地址**。<br>

所以想同时运行两个程序是不可能的，关键的问题是**这两个程序都引用了绝对物理地址**。<br>

所以操作系统会给每个进程分配一套独立的虚拟地址，把进程所使用的地址隔离开来。同时会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。<br>

所以这里引出了虚拟内存地址和物理内存地址，并会通过CPU中的内存管理单元(MMU)来把虚拟转变为物理。<br>

既然有了虚拟内存地址，就要管理两者的关系，于是出现了**内存分段和分页**。<br>


## 内存分段

按照程序的逻辑将程序分为多个段。<br>

通过段表就行映射，具体看博客图，一图胜千言！<br>

分段的不足，一个是会导致外部内存碎片的产生，而正是由于外部内存碎片的产生，需要swap，所以会导致内存交换效率低下。<br>

为了解决这两个问题，**内存分页**应运而生！<br>


## 内存分页

分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小，可以解决分段的外部内存碎片和内存交换效率低的问题:

1. 采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。
2. 存在内部碎片，但是这相对于外部碎片的内存浪费现象还是可以接受的。
3. 内存空间不足时，会出现页面的换入换出。一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。
4. 分页在加载程序的时候不需要一次性把所有页面加载到物理内存中，只有在程序运行发生缺页的时候，才真正根据页表把虚拟内存中的数据和指令加载到物理内存中。

地址映射通过页表实现，一图胜千言！<br>

但是简单分页是存在缺陷的，举了一个例子(最常见的例子了)说明简单分页会导致页表十分庞大，所以出现了**多级页表**。<br>


### 多级页表

多级列表可以节省内存的关键在于**局部性原理**，即每个程序使用到的空间远未达到其虚拟内存空间的大小。所以会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。<br>

**为什么不分级的页表做不到节约内存呢？**<br>

首先，**页表承担的职责是将虚拟地址翻译成物理地址**，所以页表一定要覆盖全部虚拟地址空间。对于不分级页表，需要创建可以覆盖所有内存的页表项来映射；而对于多级页表，只需创建一级页表就可以覆盖全部内存空间，二级甚至更高级的页表，可以在需要时再创建。<br>


### TLB

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，所以出现了TLB(Translation Lookaside Buffer)。<br>

利用的也是局部性原理，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。因此把最常访问的几个页表项存储到访问速度更快的硬件，即TLB(也就是CPU中的cache)。<br>

有了TLB后，那么CPU在寻址时，会先查TLB，如果没找到，才会继续查内存中常规的页表。<br>


## 段页式内存管理

管理方式：

1. 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制
2. 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页

地址结构：**段号、段内页号和页内位移**<br>


# malloc如何分配内存

首先要明确一点，malloc分配的是**虚拟内存**，而不是物理内存，只有访问已分配的虚拟地址空间才会分配物理内存。<br>

malloc分配内存有两种方式：

1. brk()：通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间
2. mmap()：通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存

何时用哪种方式：

1. 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存
2. 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存

为什么？<br>

1. 首先要解释下brk和mmap两种分配方式的原理(指针和映射)，引出brk是在一个连续的内存空间分配的，mmap可以分配在堆的任意地址
2. 其次说明小地址的分配相对于大块地址的分配是比较频繁的
3. malloc分配的时候会分配更大的空间作为内存池，free的时候brk和mmap的区别
4. 如果小于128KB的时候使用mmap，因为小空间申请频繁，而每次free后都会将内存归还操作系统，导致每次都要内存调用、而且实际访问的时候缺页
5. 如果大于128KB的时候使用brk，因为每次free的时候brk的内存是放回内存池的，如果长时间没有进程或线程申请大于128KB的空间，将会导致内存浪费的问题

**联想面试题的答案**！<br>
使用malloc分配的时候会分配更大的空间作为**内存池**，同时返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节。所以free() 函数只传入一个内存地址，就能知道要释放多大的内存。因为这个多出来的 16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。这样当执行 free() 函数时，free 会对传入进来的内存地址向左偏移 16 字节，然后从这个 16 字节的分析出当前的内存块的大小，自然就知道要释放多大的内存了。<br>

malloc 申请的内存，free 释放内存会归还给操作系统吗？

1. malloc 通过 brk() 方式申请的内存，free 释放内存的时候，并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用；
2. malloc 通过 mmap() 方式申请的内存，free 释放内存的时候，会把内存归还给操作系统，内存得到真正的释放。

可以解释以下两个问题：

1. 为什么不全部使用 mmap 来分配内存？
2. 为什么不全部使用 brk 来分配内存？


# 内存满了会发生什么

malloc -> 虚拟内存映射到物理内存 -> 缺页中断 -> 有空闲物理内存则分配，没有就开始回收内存

1. 后台内存回收
2. 直接内存回收

直接内存回收后都不行就会触发 **OOM** 机制。<br>

可以回收的内存：

1. 文件页：干净页和脏页
2. 匿名页：swap机制

回收都是基于LRU算法，这里又可以结合 [如何避免预读失效和缓存污染](#如何避免预读失效和缓存污染) 展开叙述<br>

回收是会带来性能影响的，常见解决方式如下：

1. 调整文件页和匿名页的回收倾向
2. 尽早触发 kswapd 内核线程异步回收内存(三个内存阈值)
3. NUMA 架构下的内存回收策略


# 在 4GB 物理内存的机器上，申请 8G 内存会怎么样

32or64位地址，有无swap分区<br>


# 如何避免预读失效和缓存污染

传统LRU算法：只有一个链表 -> 预读失效 -> 改为两个链表，active list和inactive list -> 只访问一次就将数据加入到活跃LRU链表头部，会导致缓存污染 -> 在内存页被访问第二次的时候，才将页从 inactive list 升级到 active list 里
